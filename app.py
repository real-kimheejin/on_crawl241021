import streamlit as st
import requests
from bs4 import BeautifulSoup
import re
import zipfile
import io
import os
from urllib.parse import unquote
import time
import pandas as pd

def create_zip(image_urls, address):
    zip_buffer = io.BytesIO()
    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
        total_images = len(image_urls)
        
        # ì§„í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸
        progress_bar = st.progress(0)
        status_text = st.empty()

        for idx, url in enumerate(image_urls, 1):
            try:
                progress = int((idx / total_images) * 100)
                progress_bar.progress(progress)
                status_text.text(f"ZIP íŒŒì¼ ìƒì„± ì¤‘... ({idx}/{total_images})")
                
                # ë””ë²„ê¹…: í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ URL ì¶œë ¥
                st.write(f"ë‹¤ìš´ë¡œë“œ ì‹œë„ ì¤‘: {url}")
                
                # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                    'Referer': 'https://www.onhouse.com/',
                    'Origin': 'https://www.onhouse.com',
                    'Accept': 'image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8',
                    'Accept-Encoding': 'gzip, deflate, br',
                    'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
                    'sec-ch-ua': '"Not_A Brand";v="8", "Chromium";v="120"',
                    'sec-ch-ua-mobile': '?0',
                    'sec-ch-ua-platform': '"macOS"',
                    'Sec-Fetch-Dest': 'image',
                    'Sec-Fetch-Mode': 'no-cors',
                    'Sec-Fetch-Site': 'cross-site'
                }
                response = requests.get(url, headers=headers)
                
                # ë””ë²„ê¹…: ì‘ë‹µ ìƒíƒœ ì½”ë“œ ì¶œë ¥
                st.write(f"ì‘ë‹µ ìƒíƒœ ì½”ë“œ: {response.status_code}")
                
                if response.status_code == 200:
                    image_data = response.content
                    filename = f"image_{idx}.jpg"
                    zip_file.writestr(filename, image_data)
                    st.write(f"âœ“ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {filename}")
                else:
                    st.error(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ - ìƒíƒœ ì½”ë“œ: {response.status_code}")
                    
            except Exception as e:
                st.error(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

        # ì™„ë£Œ í›„ ìƒíƒœ í…ìŠ¤íŠ¸ì™€ í”„ë¡œê·¸ë ˆìŠ¤ ë°” ì œê±°
        status_text.empty()
        progress_bar.empty()
        st.success(f"âœ… {address} ë§¤ë¬¼ ì´ë¯¸ì§€ ZIP íŒŒì¼ ìƒì„± ì™„ë£Œ!")
    
    zip_buffer.seek(0)
    return zip_buffer.getvalue()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(layout="wide", page_title="HTML ì´ë¯¸ì§€ ì¶”ì¶œê¸°")

# ì œëª© ë° ì„¤ëª…
st.title("ğŸ  ë¶€ë™ì‚° ë§¤ë¬¼ ì´ë¯¸ì§€ ì¶”ì¶œê¸°")
st.markdown("HTML ì†ŒìŠ¤ë“œë¥¼ ì…ë ¥í•˜ë©´ ì´ë¯¸ì§€ë¥¼ ì¶”ì¶œí•˜ì—¬ ZIP íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# HTML ì…ë ¥ ì˜ì—­
image_urls = []

html_source = st.text_area(
    "HTML > body íƒœê·¸ë¥¼ ë³µì‚¬í•´ì„œ ì…ë ¥í•˜ì„¸ìš”", 
height=200, 
placeholder="HTML > body íƒœê·¸ë¥¼ ë³µì‚¬í•´ì„œ ì…ë ¥í•˜ì„¸ìš”"
)



if st.button("ì´ë¯¸ì§€ ì¶”ì¶œí•˜ê¸°", type="primary", use_container_width=True, disabled=len(image_urls)):
    if html_source:
        # ì „ì²´ ì§„í–‰ìƒí™©ì„ ë³´ì—¬ì£¼ëŠ” í”„ë¡œê·¸ë ˆìŠ¤ ë°”
        progress_bar = st.progress(0)
        status_text = st.empty()  # ìƒíƒœ í…ìŠ¤íŠ¸ë¥¼ ìœ„í•œ ë¹ˆ ê³µê°„
        
        # HTML íŒŒì‹± (10%)
        time.sleep(0.5)
        status_text.text("ğŸ” HTML íŒŒì‹± ì¤‘...")
        progress_bar.progress(10)
        soup = BeautifulSoup(html_source, 'html.parser')
        
        # ë””ë²„ê¹…: HTML íŒŒì‹± ê²°ê³¼ í™•ì¸
        st.write(f"ğŸ” HTML ê¸¸ì´: {len(html_source)}ì")
        
        # ì£¼ì†Œ ì¶”ì¶œ (20%)
        time.sleep(0.5)
        status_text.text("ğŸ“ ì£¼ì†Œ ì¶”ì¶œ ì¤‘...")
        progress_bar.progress(20)
        addr_elem = soup.find('h6', class_='addr_title')
        address = addr_elem.text if addr_elem else "ì£¼ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
        
        # ì´ë¯¸ì§€ URL ì¶”ì¶œ ì‹œì‘ (30%)
        time.sleep(0.5)
        status_text.text("ğŸ–¼ï¸ ì´ë¯¸ì§€ URL ì¶”ì¶œ ì¤‘...")
        progress_bar.progress(30)
        
        # style ì†ì„±ì—ì„œ background-image URL ì°¾ê¸°
        elements_with_style = soup.find_all(lambda tag: tag.get('style') and 'background-image: url("https:' in tag.get('style'))
        total_elements = len(elements_with_style)

        for idx, element in enumerate(elements_with_style):
            style = element.get('style', '')
            # ìˆ˜ì •ëœ ì •ê·œì‹ íŒ¨í„´: ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ë¥¼ í¬í•¨í•œ URLë„ ë§¤ì¹­
            url_match = re.search(r'background-image: url\("(https:[^"]+)"\)', style)
            if url_match:
                image_url = url_match.group(1)
                # ê¸°ë³¸ URLë§Œ ì €ì¥ (ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì œê±°)
                base_url = image_url.split('?')[0]
                if base_url.lower().endswith(('.jpg', '.jpeg')):
                    image_urls.append(base_url)
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (30% ~ 90%)
            progress = 40 + (40 * (idx + 1) / total_elements)
            progress_bar.progress(int(progress))
            time.sleep(0.1)
            status_text.text(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ì¶”ì¶œ ì¤‘... ({idx + 1}/{total_elements})")
        
        # ê²°ê³¼ í‘œì‹œ
        st.success(f"âœ… {len(image_urls)}ê°œ ì´ë¯¸ì§€ ì¶”ì¶œ ì™„ë£Œ!")
        
        # ì™„ë£Œ (100%)
        progress_bar.empty()
        status_text.empty()
        
        # ì£¼ì†Œì™€ ì´ë¯¸ì§€ ê°œìˆ˜ í‘œì‹œ
        col1, col2 = st.columns(2)
        with col1:
            st.info(f"ğŸ“ ì£¼ì†Œ: {address}")
        with col2:
            st.info(f"ğŸ–¼ï¸ ë°œê²¬ëœ ì´ë¯¸ì§€: {len(image_urls)}ê°œ")
        
        # URL ëª©ë¡ í‘œì‹œ
        if image_urls:
            st.markdown("### ğŸ“‹ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ")
            
            # ì„¸ì…˜ ìƒíƒœì— ë‹¤ìš´ë¡œë“œí•œ URL ì €ì¥
            if 'downloaded_urls' not in st.session_state:
                st.session_state.downloaded_urls = set()
            
            # ë‚¨ì€ URLë§Œ í‘œì‹œ
            remaining_urls = [url for url in image_urls if url not in st.session_state.downloaded_urls]
            
            if remaining_urls:
                for idx, url in enumerate(remaining_urls, 1):
                    with st.form(key=f"form_{url}"):
                        if st.form_submit_button(
                            label=f"ğŸ“¥ {idx}ë²ˆì§¸ ì´ë¯¸ì§€",
                            type="primary",
                            use_container_width=True
                        ):
                            # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë¡œì§
                            try:
                                response = requests.get(url)
                                if response.status_code == 200:
                                    st.download_button(
                                        label="â¬‡ï¸ í´ë¦­í•˜ì—¬ ì €ì¥",
                                        data=response.content,
                                        file_name=f"image_{idx}.jpg",
                                        mime="image/jpeg",
                                        key=f"download_{url}",
                                        use_container_width=True
                                    )
                                    st.session_state.downloaded_urls.add(url)
                            except Exception as e:
                                st.error(f"ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            else:
                st.success("âœ… ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí–ˆìŠµë‹ˆë‹¤!")

    else:
        st.warning("HTML ì†ŒìŠ¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# í‘¸í„° ì¶”ê°€
st.markdown("---")
st.markdown("Made with ğŸ› ï¸ by HJ")

